{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GustavoBD-Dev/AnalyticalModelsWithPythonCourse/blob/Session-4/12_Scaling%26Normalization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Escalado y normalización de datos**"
      ],
      "metadata": {
        "id": "esVxk_bHKpfT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El escalado y la normalización son pasos críticos en el preprocesamiento de datos para modelos analíticos, especialmente cuando se utilizan algoritmos de aprendizaje automático que son sensibles a la magnitud o distribución de los datos, como el Análisis de Componentes Principales (PCA) o los modelos de regresión lineal.\n",
        "\n",
        "#### **1. Escalado de Datos**\n",
        "\n",
        "El escalado de datos implica transformar las características para que todas tengan una escala similar. Esto es esencial cuando las características tienen diferentes unidades o rangos, ya que muchos algoritmos de aprendizaje automático utilizan distancias para determinar relaciones y patrones.\n",
        "\n",
        "##### **Ejemplo:**\n",
        "Consideremos un conjunto de datos con dos características: `salario` (en miles de dólares) y `años de experiencia`. Supongamos que los valores para el `salario` oscilan entre 30 y 150, mientras que los `años de experiencia` varían entre 1 y 20. Dado que estas características tienen rangos muy diferentes, los algoritmos que dependen de distancias podrían verse sesgados hacia la característica con mayor magnitud.\n",
        "\n",
        "#### **Técnicas de Escalado:**\n",
        "- **Min-Max Scaling:** Esta técnica reescala los valores de las características al rango [0, 1]. La fórmula es:\n",
        "  `(valor - min) / (max - min)`, donde `min` y `max` son los valores mínimo y máximo de la característica.\n",
        "\n",
        "- **Standard Scaling (Estandarización):** Esta técnica transforma los datos para que tengan una media de 0 y una desviación estándar de 1. La fórmula es:\n",
        "  `(valor - media) / desviacion_estandar`.\n",
        "\n",
        "##### **Código Ejemplo en Python:**\n",
        "```python\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "\n",
        "# Datos de ejemplo\n",
        "import numpy as np\n",
        "data = np.array([[40, 5], [90, 10], [60, 7]])\n",
        "\n",
        "# Min-Max Scaling\n",
        "min_max_scaler = MinMaxScaler()\n",
        "data_min_max_scaled = min_max_scaler.fit_transform(data)\n",
        "\n",
        "# Standard Scaling\n",
        "standard_scaler = StandardScaler()\n",
        "data_standard_scaled = standard_scaler.fit_transform(data)\n",
        "```\n",
        "\n",
        "#### **2. Normalización de Datos**\n",
        "\n",
        "La normalización ajusta los datos para que sigan una distribución específica, comúnmente una distribución normal. Esto es útil cuando los algoritmos asumen que los datos están distribuidos de manera normal o cuando se quiere evitar que características con rangos amplios dominen el modelo.\n",
        "\n",
        "##### **Ejemplo:**\n",
        "Si una característica sigue una distribución muy sesgada, la normalización puede transformar estos datos para que tengan una distribución más simétrica y centrada.\n",
        "\n",
        "#### **Técnicas de Normalización:**\n",
        "- **Normalización Z-Score:** Esta técnica es la más común y transforma los datos para que tengan una media de 0 y una desviación estándar de 1, como en la estandarización.\n",
        "  \n",
        "- **Normalización Min-Max:** Similar a la usada en el escalado, ajusta los datos para que estén dentro de un rango específico, usualmente [0, 1].\n",
        "\n",
        "- **Normalización Logarítmica:** Se aplica una función logarítmica para transformar características que tienen distribuciones sesgadas positivamente. Esto reduce el efecto de valores atípicos grandes.\n",
        "\n",
        "##### **Código Ejemplo en Python:**\n",
        "```python\n",
        "import numpy as np\n",
        "\n",
        "# Datos de ejemplo\n",
        "data = np.array([1, 2, 3, 100])\n",
        "\n",
        "# Normalización Logarítmica\n",
        "data_log_normalized = np.log(data + 1)\n",
        "```\n",
        "\n",
        "### **Mejores Prácticas y Consideraciones:**\n",
        "\n",
        "- **Consistencia:** Aplicar el mismo tipo de escalado o normalización a todas las características relevantes y mantenerlo consistente durante el entrenamiento y la evaluación del modelo.\n",
        "  \n",
        "- **Comprensión del Contexto:** El tipo de escalado o normalización elegido debe depender del contexto del problema y del modelo. Por ejemplo, el escalado Min-Max es preferible si los datos están acotados en un rango específico.\n",
        "\n",
        "- **No Escalar Variables Dummies:** Las variables categóricas codificadas como dummies (0 y 1) no deben ser escaladas ni normalizadas, ya que su interpretación perdería sentido.\n",
        "\n",
        "- **Escalado después de la división de datos:** Si se dividen los datos en conjuntos de entrenamiento y prueba, el escalado o normalización debe aplicarse solo en el conjunto de entrenamiento y luego en el conjunto de prueba usando los parámetros del entrenamiento para evitar el data leakage."
      ],
      "metadata": {
        "id": "wVcHUIwWKpb_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Ejercicios**"
      ],
      "metadata": {
        "id": "CtYFUg7ZPFvB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "file_id = '1GxFpnjaEPauGQ0PRe-YTzjhDaCwd-wTN'\n",
        "raw_url = f'https://drive.google.com/uc?id={file_id}&export=download'\n",
        "\n",
        "import pandas as pd\n",
        "data = pd.read_csv(raw_url)\n",
        "\n",
        "print(data.head())"
      ],
      "metadata": {
        "id": "CyUoIpAsWYQ0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "adfb5393-bf84-465a-a65a-01a8d0fa8878"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "   User_ID Product_ID Gender   Age  Occupation City_Category  \\\n",
            "0  1000001  P00069042      F  0-17          10             A   \n",
            "1  1000001  P00248942      F  0-17          10             A   \n",
            "2  1000001  P00087842      F  0-17          10             A   \n",
            "3  1000001  P00085442      F  0-17          10             A   \n",
            "4  1000002  P00285442      M   55+          16             C   \n",
            "\n",
            "  Stay_In_Current_City_Years  Marital_Status  Product_Category_1  \\\n",
            "0                          2               0                   3   \n",
            "1                          2               0                   1   \n",
            "2                          2               0                  12   \n",
            "3                          2               0                  12   \n",
            "4                         4+               0                   8   \n",
            "\n",
            "   Product_Category_2  Product_Category_3  Purchase  \n",
            "0                 NaN                 NaN      8370  \n",
            "1                 6.0                14.0     15200  \n",
            "2                 NaN                 NaN      1422  \n",
            "3                14.0                 NaN      1057  \n",
            "4                 NaN                 NaN      7969  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Ejercicio 1: Escalado de los valores de \"Purchase\"**\n",
        "**Objetivo:** Aplicar Min-Max Scaling para escalar los valores de la columna \"Purchase\" en un rango de 0 a 1."
      ],
      "metadata": {
        "id": "JjePGR7fQSEp"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Yr1k_WUNQR2p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Ejercicio 2: Estandarización de \"Occupation\"**\n",
        "**Objetivo:** Estandarizar la columna \"Occupation\" para que tenga una media de 0 y una desviación estándar de 1."
      ],
      "metadata": {
        "id": "f8OIqWzDQRpH"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fuw5LbYqQRYG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Ejercicio 3: Normalización L2 de \"Product_Category_1\", \"Product_Category_2\" y \"Product_Category_3\"**\n",
        "**Objetivo:** Aplicar la normalización L2 a las columnas \"Product_Category_1\", \"Product_Category_2\" y \"Product_Category_3\"."
      ],
      "metadata": {
        "id": "jGu9I_8OQPIp"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ccGOroZ6QO8J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Ejercicio 4: Estandarización condicional**\n",
        "**Objetivo:** Estandarizar la columna \"Purchase\" solo para aquellos usuarios que tienen una \"Age\" mayor a 35 años."
      ],
      "metadata": {
        "id": "L1_qGnBQQOu-"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iRb7WS0vQOjN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Ejercicio 5: Escalado de múltiplos productos**\n",
        "**Objetivo:** Aplicar Min-Max Scaling a las columnas \"Product_Category_1\" y \"Product_Category_2\" de forma conjunta."
      ],
      "metadata": {
        "id": "LbRTZlk-QOWI"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wICV5SYaQOJD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Ejercicio 6: Estandarización y Escalado Combinado**\n",
        "**Objetivo:** Estandarizar la columna \"Occupation\" y luego escalar los resultados entre 0 y 1."
      ],
      "metadata": {
        "id": "wvuo4LLHQN7q"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cT9uUBWzQNun"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Ejercicio 7: Escalado basado en grupos**\n",
        "**Objetivo:** Aplicar Min-Max Scaling a la columna \"Purchase\", pero de manera independiente para cada categoría de \"City_Category\"."
      ],
      "metadata": {
        "id": "Nnks-3LNQNg_"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DETKnXGiQNUH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Ejercicio 8: Normalización de múltiples columnas**\n",
        "**Objetivo:** Aplicar normalización L1 a las columnas \"Product_Category_1\", \"Product_Category_2\" y \"Product_Category_3\"."
      ],
      "metadata": {
        "id": "oqg5MwcNQNGk"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DH2X_435QM4u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Ejercicio 9: Escalado de datos con outliers**\n",
        "**Objetivo:** Comparar el impacto del Min-Max Scaling y la Estandarización en la columna \"Purchase\" considerando la presencia de posibles outliers."
      ],
      "metadata": {
        "id": "GyAnaM6zQMqs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z0NWMhVuKhMR"
      },
      "outputs": [],
      "source": []
    }
  ]
}