{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GustavoBD-Dev/AnalyticalModelsWithPythonCourse/blob/Session-5/15_ScikitLearn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Introducción a Scikit-learn**"
      ],
      "metadata": {
        "id": "gX29mPgRtTU6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scikit-learn es una de las bibliotecas más populares para el aprendizaje automático en Python. Ofrece herramientas simples y eficientes para el análisis y modelado de datos, además de ser altamente compatible con otras bibliotecas como NumPy y pandas. Scikit-learn es ideal tanto para principiantes como para expertos en el campo, ya que proporciona una interfaz consistente y fácil de usar para construir, entrenar y evaluar modelos de machine learning.\n",
        "\n",
        "###**Instalación**\n",
        "\n",
        "Para instalar Scikit-learn, puedes utilizar pip:\n",
        "\n",
        "```python\n",
        "pip install scikit-learn\n",
        "```\n",
        "\n",
        "###**Principales características**\n",
        "\n",
        "1. **Modelos de aprendizaje automático**: Scikit-learn incluye una amplia gama de algoritmos de machine learning como regresión, clasificación, clustering y reducción de dimensionalidad.\n",
        "\n",
        "2. **Herramientas para preprocesamiento de datos**: Permite la normalización, escalado, codificación de variables categóricas y manejo de valores faltantes, entre otros.\n",
        "\n",
        "3. **Evaluación de modelos**: Scikit-learn facilita la evaluación de modelos mediante métricas de desempeño como accuracy, precision, recall y más, además de técnicas como cross-validation.\n",
        "\n",
        "4. **Pipelines**: Permite construir flujos de trabajo complejos que integran diferentes pasos de preprocesamiento y modelado de forma secuencial.\n",
        "\n",
        "###**Ejemplos prácticos**\n",
        "\n",
        "#### 1. **Entrenamiento de un modelo de clasificación**\n",
        "\n",
        "Vamos a entrenar un modelo de clasificación utilizando el famoso dataset de iris.\n",
        "\n",
        "```python\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Cargar el dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Crear el modelo\n",
        "model = RandomForestClassifier()\n",
        "\n",
        "# Entrenar el modelo\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predecir los valores de prueba\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluar el modelo\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "```\n",
        "\n",
        "**Mejores prácticas:**\n",
        "\n",
        "- **Dividir los datos en conjuntos de entrenamiento y prueba**: Siempre debes evaluar el rendimiento de tu modelo en un conjunto de datos que no haya visto durante el entrenamiento para evitar el sobreajuste.\n",
        "- **Ajuste de hiperparámetros**: Utiliza técnicas como GridSearchCV para encontrar los mejores hiperparámetros para tu modelo.\n",
        "- **Validación cruzada**: Implementa cross-validation para asegurarte de que tu modelo generaliza bien.\n",
        "\n",
        "#### 2. **Pipeline de preprocesamiento y modelado**\n",
        "\n",
        "Los Pipelines son una herramienta poderosa para simplificar el flujo de trabajo, combinando múltiples pasos en un solo objeto.\n",
        "\n",
        "```python\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# Crear un pipeline con escalado de datos y un clasificador SVM\n",
        "pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('svm', SVC())\n",
        "])\n",
        "\n",
        "# Entrenar el pipeline\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Predecir y evaluar\n",
        "y_pred = pipeline.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy with Pipeline: {accuracy}\")\n",
        "```\n",
        "\n",
        "**Mejores prácticas:**\n",
        "\n",
        "- **Uso de Pipelines**: Los Pipelines aseguran que las transformaciones de datos se apliquen de manera consistente en los conjuntos de entrenamiento y prueba.\n",
        "- **Estandarización de datos**: Cuando trabajas con algoritmos que dependen de la escala de los datos (como SVM o regresión logística), siempre es recomendable escalar los datos.\n",
        "\n",
        "### Consideraciones indispensables\n",
        "\n",
        "- **Compatibilidad con otras bibliotecas**: Scikit-learn se integra perfectamente con bibliotecas como pandas para la manipulación de datos y NumPy para operaciones matemáticas.\n",
        "- **Simplicidad y flexibilidad**: Ofrece una API simple y consistente, lo que facilita el cambio entre diferentes modelos y la experimentación.\n",
        "- **Documentación extensa**: La documentación de Scikit-learn es completa y está llena de ejemplos, lo que es invaluable para aprender y aplicar técnicas avanzadas."
      ],
      "metadata": {
        "id": "4-Ov4tuKtTS0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Ejercicios:**"
      ],
      "metadata": {
        "id": "ZLUSbk5wFCp_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ik8bCMjrs_Ai",
        "outputId": "7a604a24-b8ec-46e2-9bf5-ed191ce7179f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "   User_ID Product_ID Gender   Age  Occupation City_Category  \\\n",
            "0  1000001  P00069042      F  0-17          10             A   \n",
            "1  1000001  P00248942      F  0-17          10             A   \n",
            "2  1000001  P00087842      F  0-17          10             A   \n",
            "3  1000001  P00085442      F  0-17          10             A   \n",
            "4  1000002  P00285442      M   55+          16             C   \n",
            "\n",
            "  Stay_In_Current_City_Years  Marital_Status  Product_Category_1  \\\n",
            "0                          2               0                   3   \n",
            "1                          2               0                   1   \n",
            "2                          2               0                  12   \n",
            "3                          2               0                  12   \n",
            "4                         4+               0                   8   \n",
            "\n",
            "   Product_Category_2  Product_Category_3  Purchase  \n",
            "0                 NaN                 NaN      8370  \n",
            "1                 6.0                14.0     15200  \n",
            "2                 NaN                 NaN      1422  \n",
            "3                14.0                 NaN      1057  \n",
            "4                 NaN                 NaN      7969  \n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "file_id = '1GxFpnjaEPauGQ0PRe-YTzjhDaCwd-wTN'\n",
        "raw_url = f'https://drive.google.com/uc?id={file_id}&export=download'\n",
        "\n",
        "import pandas as pd\n",
        "data = pd.read_csv(raw_url)\n",
        "\n",
        "print(data.head())\n",
        "\n",
        "df=data.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Ejercicio 1: Ingeniería de Características con ColumnTransformer**\n",
        "**Objetivo:** Aplicar transformaciones diferentes a distintas columnas del dataset en un solo paso."
      ],
      "metadata": {
        "id": "7MemUZ7xGLnL"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zxrS_AnMGLhW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Ejercicio 2: Implementación de Pipelines con Preprocesamiento y Modelado**\n",
        "**Objetivo:** Crear un pipeline que combine preprocesamiento de datos y entrenamiento de un modelo."
      ],
      "metadata": {
        "id": "-gwwjmbHGLbA"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VGfVqgD-GLWE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Ejercicio 3: Evaluación de Modelos con Validación Cruzada Estratificada**\n",
        "**Objetivo:** Usar validación cruzada estratificada para evaluar el desempeño de un modelo."
      ],
      "metadata": {
        "id": "SuYTUjzxGLQe"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YGfmlHCyGLLS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Ejercicio 4: Optimización de Hiperparámetros con GridSearchCV**\n",
        "**Objetivo:** Ajustar los hiperparámetros de un modelo para maximizar su desempeño."
      ],
      "metadata": {
        "id": "Id2s3dOoGLFV"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JWqzLKFWGLAK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Ejercicio 5: Selección de Características con SelectFromModel**\n",
        "**Objetivo:** Identificar y seleccionar automáticamente las características más importantes."
      ],
      "metadata": {
        "id": "U5uv1Y0QGK5m"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jwtOnS1iGK0Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Ejercicio 6: Análisis de Componentes Principales (PCA) para Reducción de Dimensionalidad**\n",
        "**Objetivo:** Aplicar PCA para reducir la dimensionalidad del dataset."
      ],
      "metadata": {
        "id": "yVQ3Wfk3GKtL"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "szJRkIQkGKn6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Ejercicio 7: Clasificación de Productos con KNeighborsClassifier**\n",
        "**Objetivo:** Implementar un modelo k-NN para clasificar las compras basadas en características del cliente."
      ],
      "metadata": {
        "id": "1sCSpLTnGKhm"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QXaG4pWiGKbY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Ejercicio 8: Implementación de un Ensamble con VotingClassifier**\n",
        "**Objetivo:** Combinar múltiples modelos para mejorar el desempeño de clasificación."
      ],
      "metadata": {
        "id": "wxkzBfrgGKTZ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LsJe5bucGKNt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Ejercicio 9: Evaluación de un Modelo con Matriz de Confusión y Reporte de Clasificación**\n",
        "**Objetivo:** Evaluar el desempeño de un modelo usando una matriz de confusión y un reporte de clasificación."
      ],
      "metadata": {
        "id": "jcgDh0u4GKHO"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p7IAUBqjGKAE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}